{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting tweets from spritzer archive and annotating Migration relevant tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This segment defining methods for extracting the tweets from Spritzer archive which are compressed in bzip2 format,\n",
    "# and then pre-filter tweets based on certain criterias and finally annotating them.\n",
    "import json, os, bz2,nltk\n",
    "import unicodecsv as csv\n",
    "import re\n",
    "import numpy as np\n",
    "import locale\n",
    "locale.getdefaultlocale()\n",
    "directory = 'G:/archiveteam-twitter-stream-2015-09/2015/09/13/12' #the directory where you stored spritzer Data. Also, change all \\ to /\n",
    "#outfile2='migranttext.txt' #stores tweet text, just for reference\n",
    "outfile = 'migrantinfo_13_12.json' #stores json in newline json format\n",
    "labelledJsonFile = 'migrantLabelled_13_12.json' # stores labelled Json after the annotation process\n",
    "TimeZone=['','Amsterdam', 'Andorra', 'Astrakhan', 'Athens', 'Belfast', 'Belgrade', 'Berlin', 'Bratislava', 'Brussels', 'Bucharest', 'Budapest', 'Busingen', 'Chisinau', 'Copenhagen', 'Dublin', 'Gibraltar', 'Guernsey', 'Helsinki', 'Isle_of_Man', 'Istanbul', 'Jersey', 'Kaliningrad', 'Kiev', 'Kirov', 'Lisbon', 'Ljubljana', 'London', 'Luxembourg', 'Madrid', 'Malta', 'Mariehamn', 'Minsk', 'Monaco', 'Moscow', 'Asia/Nicosia', 'Oslo', 'Paris', 'Podgorica', 'Prague', 'Riga', 'Rome', 'Samara', 'San_Marino', 'Sarajevo', 'Saratov', 'Simferopol', 'Skopje', 'Sofia', 'Stockholm', 'Tallinn', 'Tirane', 'Tiraspol', 'Ulyanovsk', 'Uzhgorod', 'Vaduz', 'Vatican', 'Vienna', 'Vilnius', 'Volgograd', 'Warsaw', 'Zagreb', 'Zaporozhye', 'Zurich']\n",
    "#As GPS location didnt provide information regarding user location in most cases, we madde use of timezone field to consider data only of europe.\n",
    "pattern=r'(((((i|e)m)?)migra(t|n).)|(refuge.)|(as+yl+um))'\n",
    "def process_json(pattern,directory,outfile):\n",
    "    with open(outfile, 'w',encoding='utf8') as jsonfile:\n",
    "        #with open(outfile2, 'w',encoding='utf8') as json2file:\n",
    "            for dirs, subdirs, files in os.walk(directory):\n",
    "                    for file in files:\n",
    "                        if file.endswith('.bz2'):\n",
    "                            file = bz2.BZ2File(os.path.join(dirs, file), 'r')\n",
    "                            print(file)\n",
    "                            for line in file:\n",
    "                                status=0\n",
    "                                #for keyword in keywords:\n",
    "                                tweet = json.loads(line)\n",
    "                                if('lang' in tweet):\n",
    "                                    if(tweet['lang']=='en'):\n",
    "                                        for zone in TimeZone:\n",
    "                                            if(tweet['user']['time_zone']==zone):\n",
    "                                                if re.search(pattern, tweet['text'].lower()):\n",
    "                                                    status=1\n",
    "                                if status==1:\n",
    "                                    tweet_text=tweet['text']\n",
    "                                    stri = json.dumps(tweet, sort_keys=True, ensure_ascii=False)\n",
    "                                    jsonfile.write(stri+\"\\n\")\n",
    "            jsonfile.close()\n",
    "def annotatejson(outfile,labelledJsonFile):\n",
    "    with open(outfile, 'r',encoding='utf8') as jsonfile:\n",
    "        with open(labelledJsonFile, 'w',encoding='utf8') as labelledFile:\n",
    "            for line in jsonfile:\n",
    "                    tweet = json.loads(line)\n",
    "                    print(tweet['text'])\n",
    "                    x = input(\"Click 1 if relevant, 0 if no : \")\n",
    "                    while not (x==\"1\" or x==\"0\"):\n",
    "                        print(\"Wrong inputs\")\n",
    "                        x=input(\"Click 1 if relevant, 0 if no : \")\n",
    "                    tweet['label']=x\n",
    "                    stri = json.dumps(tweet, sort_keys=True, ensure_ascii=False)\n",
    "                    labelledFile.write(stri+\"\\n\")\n",
    "            labelledFile.close()\n",
    "            jsonfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_json(pattern,directory,outfile) # to filter migration related tweets from the spritzer archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory = 'G:/archiveteam-twitter-stream-2015-09/2015/09/13/12' #change folder\n",
    "outfile = 'migrantrandomsur.json' #add a number for every run so we dont overwrite it.(The number should be folder number)\n",
    "labelledJsonFile = 'migrantrandomsur_labelled_by_chai.json' #add a number for every run so we dont overwrite it.(The number should be folder number)\n",
    "annotatejson(outfile,labelledJsonFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
